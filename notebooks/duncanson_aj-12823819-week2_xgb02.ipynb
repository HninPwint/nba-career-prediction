{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA Career Prediction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = 'xgb02a'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim:\n",
    "* To improve on xgb01, by using imblearn\n",
    "* To improve on 0.71259 on Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "\n",
    "Retain -ve values, apply SMOTE & under sampling pipeline, search on roc_auc.\n",
    "Results train, val auc:\n",
    "* SMOTE, under = 0.50, 0.75 : 0.73, 0.70\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load  # simpler than pickle!\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "data_path = '../data/raw/uts-advdsi-nba-career-prediction'\n",
    "\n",
    "train_raw = pd.read_csv(data_path + '/train.csv')\n",
    "test_raw = pd.read_csv(data_path + '/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 22)\n",
      "(3799, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10556</td>\n",
       "      <td>3799</td>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5342</td>\n",
       "      <td>3800</td>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5716</td>\n",
       "      <td>3801</td>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13790</td>\n",
       "      <td>3802</td>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5470</td>\n",
       "      <td>3803</td>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_old    Id  GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA  ...  FTA   FT%  \\\n",
       "0   10556  3799  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  ...  2.9  72.1   \n",
       "1    5342  3800  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  ...  3.6  67.8   \n",
       "2    5716  3801  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  ...  0.6  75.7   \n",
       "3   13790  3802  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  ...  1.5  66.9   \n",
       "4    5470  3803  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  ...  0.5  54.0   \n",
       "\n",
       "   OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.2   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.6   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   0.6   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   0.8   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.4   2.7  4.9  0.4  0.4  0.6  0.7            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shapes & head\n",
    "\n",
    "print(train_raw.shape)\n",
    "print(test_raw.shape)\n",
    "\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8194</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8196</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8197</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_old  Id  GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA  ...  FTM  FTA  \\\n",
       "0       1   0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3  ...  0.7  1.2   \n",
       "1    8194   1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  ...  1.8  2.5   \n",
       "2       3   2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  ...  1.8  2.7   \n",
       "3    8196   3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  ...  4.5  6.3   \n",
       "4    8197   4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  ...  1.1  1.3   \n",
       "\n",
       "    FT%  OREB  DREB  REB  AST  STL  BLK  TOV  \n",
       "0  63.4   1.2   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1  75.3   0.5   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2  71.2   1.3   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3  70.9   1.5   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4  76.9   0.2   0.6  0.9  1.5  0.5 -0.4  0.9  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 22 columns):\n",
      "Id_old         8000 non-null int64\n",
      "Id             8000 non-null int64\n",
      "GP             8000 non-null int64\n",
      "MIN            8000 non-null float64\n",
      "PTS            8000 non-null float64\n",
      "FGM            8000 non-null float64\n",
      "FGA            8000 non-null float64\n",
      "FG%            8000 non-null float64\n",
      "3P Made        8000 non-null float64\n",
      "3PA            8000 non-null float64\n",
      "3P%            8000 non-null float64\n",
      "FTM            8000 non-null float64\n",
      "FTA            8000 non-null float64\n",
      "FT%            8000 non-null float64\n",
      "OREB           8000 non-null float64\n",
      "DREB           8000 non-null float64\n",
      "REB            8000 non-null float64\n",
      "AST            8000 non-null float64\n",
      "STL            8000 non-null float64\n",
      "BLK            8000 non-null float64\n",
      "TOV            8000 non-null float64\n",
      "TARGET_5Yrs    8000 non-null int64\n",
      "dtypes: float64(18), int64(4)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6856.971000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>62.777875</td>\n",
       "      <td>18.576662</td>\n",
       "      <td>7.267088</td>\n",
       "      <td>2.807037</td>\n",
       "      <td>6.231212</td>\n",
       "      <td>44.608900</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947788</td>\n",
       "      <td>71.365825</td>\n",
       "      <td>1.077838</td>\n",
       "      <td>2.168500</td>\n",
       "      <td>3.245300</td>\n",
       "      <td>1.624513</td>\n",
       "      <td>0.648687</td>\n",
       "      <td>0.245212</td>\n",
       "      <td>1.257763</td>\n",
       "      <td>0.833625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3977.447579</td>\n",
       "      <td>2309.54541</td>\n",
       "      <td>17.118774</td>\n",
       "      <td>8.935263</td>\n",
       "      <td>4.318732</td>\n",
       "      <td>1.693373</td>\n",
       "      <td>3.584559</td>\n",
       "      <td>6.155453</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>1.060964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252352</td>\n",
       "      <td>10.430447</td>\n",
       "      <td>0.785670</td>\n",
       "      <td>1.392224</td>\n",
       "      <td>2.085154</td>\n",
       "      <td>1.355986</td>\n",
       "      <td>0.407626</td>\n",
       "      <td>0.821037</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.372440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3799.00000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3413.750000</td>\n",
       "      <td>5798.75000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6787.500000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10299.250000</td>\n",
       "      <td>9798.25000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13798.000000</td>\n",
       "      <td>11798.00000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>168.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   8000.000000   8000.00000  8000.000000  8000.000000  8000.000000   \n",
       "mean    6856.971000   7798.50000    62.777875    18.576662     7.267088   \n",
       "std     3977.447579   2309.54541    17.118774     8.935263     4.318732   \n",
       "min        4.000000   3799.00000    -8.000000     2.900000     0.800000   \n",
       "25%     3413.750000   5798.75000    51.000000    12.000000     4.100000   \n",
       "50%     6787.500000   7798.50000    63.000000    16.800000     6.300000   \n",
       "75%    10299.250000   9798.25000    74.000000    23.500000     9.500000   \n",
       "max    13798.000000  11798.00000   123.000000    73.800000    34.200000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  ...   \n",
       "mean      2.807037     6.231212    44.608900     0.264525     0.816562  ...   \n",
       "std       1.693373     3.584559     6.155453     0.384093     1.060964  ...   \n",
       "min       0.300000     0.800000    21.300000    -1.100000    -3.100000  ...   \n",
       "25%       1.600000     3.600000    40.400000     0.000000     0.100000  ...   \n",
       "50%       2.400000     5.400000    44.400000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.700000     0.500000     1.500000  ...   \n",
       "max      13.100000    28.900000    67.200000     1.700000     4.700000  ...   \n",
       "\n",
       "               FTA          FT%         OREB         DREB          REB  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      1.947788    71.365825     1.077838     2.168500     3.245300   \n",
       "std       1.252352    10.430447     0.785670     1.392224     2.085154   \n",
       "min       0.000000   -13.300000     0.000000     0.200000     0.300000   \n",
       "25%       1.000000    65.000000     0.500000     1.100000     1.700000   \n",
       "50%       1.700000    71.400000     0.900000     1.900000     2.800000   \n",
       "75%       2.600000    77.500000     1.500000     2.900000     4.300000   \n",
       "max      11.100000   168.900000     5.500000    11.000000    15.900000   \n",
       "\n",
       "               AST          STL          BLK          TOV  TARGET_5Yrs  \n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  \n",
       "mean      1.624513     0.648687     0.245212     1.257763     0.833625  \n",
       "std       1.355986     0.407626     0.821037     0.723270     0.372440  \n",
       "min       0.000000     0.000000   -17.900000     0.100000     0.000000  \n",
       "25%       0.700000     0.300000     0.100000     0.700000     1.000000  \n",
       "50%       1.300000     0.600000     0.200000     1.100000     1.000000  \n",
       "75%       2.200000     0.900000     0.400000     1.600000     1.000000  \n",
       "max      12.800000     3.600000    18.900000     5.300000     1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable descriptions\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7010.614109</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>62.853909</td>\n",
       "      <td>18.650224</td>\n",
       "      <td>7.328034</td>\n",
       "      <td>2.835404</td>\n",
       "      <td>6.302580</td>\n",
       "      <td>44.599079</td>\n",
       "      <td>0.255962</td>\n",
       "      <td>0.796920</td>\n",
       "      <td>...</td>\n",
       "      <td>1.399842</td>\n",
       "      <td>1.953567</td>\n",
       "      <td>71.612924</td>\n",
       "      <td>1.096025</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>3.275783</td>\n",
       "      <td>1.636483</td>\n",
       "      <td>0.653593</td>\n",
       "      <td>0.257726</td>\n",
       "      <td>1.257910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3954.173641</td>\n",
       "      <td>1096.821164</td>\n",
       "      <td>17.151740</td>\n",
       "      <td>8.727259</td>\n",
       "      <td>4.294724</td>\n",
       "      <td>1.688427</td>\n",
       "      <td>3.579221</td>\n",
       "      <td>6.040168</td>\n",
       "      <td>0.380987</td>\n",
       "      <td>1.052862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926140</td>\n",
       "      <td>1.250376</td>\n",
       "      <td>10.457336</td>\n",
       "      <td>0.785678</td>\n",
       "      <td>1.371935</td>\n",
       "      <td>2.070646</td>\n",
       "      <td>1.335496</td>\n",
       "      <td>0.410573</td>\n",
       "      <td>0.639660</td>\n",
       "      <td>0.712449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3644.000000</td>\n",
       "      <td>949.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7062.000000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10402.500000</td>\n",
       "      <td>2848.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13792.000000</td>\n",
       "      <td>3798.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>127.100000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean    7010.614109  1899.000000    62.853909    18.650224     7.328034   \n",
       "std     3954.173641  1096.821164    17.151740     8.727259     4.294724   \n",
       "min        1.000000     0.000000     6.000000     3.700000     0.700000   \n",
       "25%     3644.000000   949.500000    51.000000    12.200000     4.200000   \n",
       "50%     7062.000000  1899.000000    63.000000    17.000000     6.400000   \n",
       "75%    10402.500000  2848.500000    74.000000    23.300000     9.400000   \n",
       "max    13792.000000  3798.000000   126.000000    68.000000    33.000000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000  ...   \n",
       "mean      2.835404     6.302580    44.599079     0.255962     0.796920  ...   \n",
       "std       1.688427     3.579221     6.040168     0.380987     1.052862  ...   \n",
       "min       0.300000     0.800000    25.100000    -1.000000    -2.700000  ...   \n",
       "25%       1.600000     3.700000    40.500000     0.000000     0.100000  ...   \n",
       "50%       2.500000     5.500000    44.600000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.500000     0.500000     1.500000  ...   \n",
       "max      13.400000    26.200000    74.600000     1.600000     4.300000  ...   \n",
       "\n",
       "               FTM          FTA          FT%         OREB         DREB  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean      1.399842     1.953567    71.612924     1.096025     2.179495   \n",
       "std       0.926140     1.250376    10.457336     0.785678     1.371935   \n",
       "min       0.000000     0.000000    23.700000     0.000000     0.200000   \n",
       "25%       0.700000     1.000000    65.000000     0.500000     1.200000   \n",
       "50%       1.200000     1.700000    71.500000     0.900000     1.900000   \n",
       "75%       1.900000     2.600000    78.000000     1.500000     2.900000   \n",
       "max       7.800000     9.800000   127.100000     6.900000    12.000000   \n",
       "\n",
       "               REB          AST          STL          BLK          TOV  \n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000  \n",
       "mean      3.275783     1.636483     0.653593     0.257726     1.257910  \n",
       "std       2.070646     1.335496     0.410573     0.639660     0.712449  \n",
       "min       0.300000     0.000000     0.000000    -7.100000     0.100000  \n",
       "25%       1.800000     0.600000     0.400000     0.100000     0.700000  \n",
       "50%       2.800000     1.300000     0.600000     0.200000     1.100000  \n",
       "75%       4.300000     2.300000     0.900000     0.400000     1.600000  \n",
       "max      18.500000     9.000000     2.700000    14.800000     5.200000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n",
    "\n",
    "We will retain all potential features, when using non-linear models.\n",
    "\n",
    "and TARGET_5Yrs is our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_raw.copy()\n",
    "test = test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['Id_old', 'Id'] #, 'MIN', 'FGM', 'FGA', 'TOV', '3PA', 'FTM', 'FTA', 'REB']\n",
    "train.drop(cols_drop, axis=1, inplace=True)\n",
    "test.drop(cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  22.6  2.0  2.9  72.1   2.2   \n",
       "1  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  34.9  2.4  3.6  67.8   3.6   \n",
       "2  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  34.3  0.4  0.6  75.7   0.6   \n",
       "3  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  23.7  0.9  1.5  66.9   0.8   \n",
       "4  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  13.7  0.2  0.5  54.0   2.4   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.7  4.9  0.4  0.4  0.6  0.7            1  "
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3   7.3  0.7  1.2  63.4   1.2   \n",
       "1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  35.1  1.8  2.5  75.3   0.5   \n",
       "2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  44.8  1.8  2.7  71.2   1.3   \n",
       "3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  13.5  4.5  6.3  70.9   1.5   \n",
       "4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4   0.6  0.9  1.5  0.5 -0.4  0.9  "
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative values do not make sense in this context\n",
    "\n",
    "def clean_negatives(strategy, df):\n",
    "    \n",
    "    if strategy=='abs':\n",
    "        df = abs(df)\n",
    "    if strategy=='null':\n",
    "        df[df < 0] = None\n",
    "    if strategy=='mean':\n",
    "        df[df < 0] = None\n",
    "        df.fillna(df.mean(), inplace=True)      \n",
    "    \n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_strategy = ''\n",
    "\n",
    "train = clean_negatives(negatives_strategy, train)\n",
    "test = clean_negatives(negatives_strategy, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  22.6  2.0  2.9  72.1   2.2   \n",
       "1  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  34.9  2.4  3.6  67.8   3.6   \n",
       "2  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  34.3  0.4  0.6  75.7   0.6   \n",
       "3  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  23.7  0.9  1.5  66.9   0.8   \n",
       "4  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  13.7  0.2  0.5  54.0   2.4   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.7  4.9  0.4  0.4  0.6  0.7            1  "
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3   7.3  0.7  1.2  63.4   1.2   \n",
       "1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  35.1  1.8  2.5  75.3   0.5   \n",
       "2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  44.8  1.8  2.7  71.2   1.3   \n",
       "3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  13.5  4.5  6.3  70.9   1.5   \n",
       "4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4   0.6  0.9  1.5  0.5 -0.4  0.9  "
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:(8000, 19)\n",
      "test:(3799, 19)\n"
     ]
    }
   ],
   "source": [
    "#examine shapes\n",
    "\n",
    "print('train:' + str(train.shape))\n",
    "print('test:' + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 6669, 0: 1331})\n"
     ]
    }
   ],
   "source": [
    "# target class balance check\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_target)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations\n",
    "\n",
    "# scaling - not for tree-based model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training data and validation data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train_target, test_size=0.2, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "#import models\n",
    "\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.010518407212622\n"
     ]
    }
   ],
   "source": [
    "#Class balancing\n",
    "\n",
    "class_weight = counter[1.0] / counter[0.0]\n",
    "print(class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "initial_model = xgb.XGBClassifier(#scale_pos_weight = class_weight,\n",
    "                                 use_label_encoder=False,\n",
    "                                 seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index the y_train, since xgboost has deprecated the use_label_encoder function\n",
    "\n",
    "y_train.index = range(0, len(y_train), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=6, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "initial_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/aj_xgb02a_initial.joblib']"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(initial_model,  '../models/aj_' + experiment_label + '_initial.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = initial_model.predict(X_train)\n",
    "y_val_preds = initial_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.models.aj_metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "        pred:0  pred:1\n",
      "true:0     937     137\n",
      "true:1       0    5326\n",
      "Val:\n",
      "        pred:0  pred:1\n",
      "true:0      23     234\n",
      "true:1      64    1279\n"
     ]
    }
   ],
   "source": [
    "# Show TRAINING confusion matrix with labels\n",
    "\n",
    "print(\"Training:\")\n",
    "print(confusion_matrix(y_train, y_train_preds))\n",
    "\n",
    "print(\"Val:\")\n",
    "print(confusion_matrix(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1074\n",
      "           1       0.97      1.00      0.99      5326\n",
      "\n",
      "    accuracy                           0.98      6400\n",
      "   macro avg       0.99      0.94      0.96      6400\n",
      "weighted avg       0.98      0.98      0.98      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.09      0.13       257\n",
      "           1       0.85      0.95      0.90      1343\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.55      0.52      0.51      1600\n",
      "weighted avg       0.75      0.81      0.77      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_train_preds))\n",
    "print(metrics.classification_report(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /opt/conda/lib/python3.7/site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# class imbalance pipeline\n",
    "\n",
    "!pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "      \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        gamma = space['gamma'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree'],\n",
    "        #scale_pos_weight = space['scale_pos_weight'],\n",
    "        use_label_encoder=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Define model pipeline\n",
    "    model = Pipeline([\n",
    "        ('over', SMOTE(sampling_strategy=0.5)),\n",
    "        ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
    "        ('model', xgboost)\n",
    "    ])\n",
    "    \n",
    "    acc = cross_val_score(model, X_train, y_train, cv=10, scoring=\"roc_auc\").mean()\n",
    "\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 20, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.05),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.1, 0.01),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "    #'scale_pos_weight' : hp.quniform('scale_pos_weight', 1, class_weight, class_weight / 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:03:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:18<00:00,  3.75s/trial, best loss: 0.3306640086236351]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "    fn=objective,   \n",
    "    space=space,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'colsample_bytree': 0.75, 'gamma': 0.0, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 3.0, 'subsample': 0.15000000000000002}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:03:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('over', SMOTE(sampling_strategy=0.5)),\n",
       "                ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.75, gamma=0.0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.05,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=3.0, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=6, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=42, subsample=0.15000000000000002,\n",
       "                               tree_method='exact', use_label_encoder=False,\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 930,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### and here is where we take the best hyperparamters from the hyperparameter search and fit the model again.\n",
    "\n",
    "xgboost_2 = xgb.XGBClassifier(\n",
    "    max_depth = best['max_depth'],\n",
    "    learning_rate = best['learning_rate'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    gamma = best['gamma'],    \n",
    "    subsample = best['subsample'],\n",
    "    colsample_bytree = best['colsample_bytree'],\n",
    "    #scale_pos_weight = best['scale_pos_weight'],\n",
    "    use_label_encoder=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define model pipeline\n",
    "best_model = Pipeline([\n",
    "    ('over', SMOTE(sampling_strategy=0.5)),\n",
    "    ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
    "    ('model', xgboost_2)\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/aj_xgb02a_best.joblib']"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model to file\n",
    "\n",
    "dump(best_model,  '../models/aj_' + experiment_label + '_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for train & validation sets\n",
    "\n",
    "y_train_preds = best_model.predict(X_train)\n",
    "y_val_preds = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "        pred:0  pred:1\n",
      "true:0     463     611\n",
      "true:1     825    4501\n",
      "Val:\n",
      "        pred:0  pred:1\n",
      "true:0      98     159\n",
      "true:1     239    1104\n"
     ]
    }
   ],
   "source": [
    "# Show TRAINING confusion matrix with labels\n",
    "\n",
    "print(\"Training:\")\n",
    "print(confusion_matrix(y_train, y_train_preds))\n",
    "\n",
    "print(\"Val:\")\n",
    "print(confusion_matrix(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.43      0.39      1074\n",
      "           1       0.88      0.85      0.86      5326\n",
      "\n",
      "    accuracy                           0.78      6400\n",
      "   macro avg       0.62      0.64      0.63      6400\n",
      "weighted avg       0.79      0.78      0.78      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.38      0.33       257\n",
      "           1       0.87      0.82      0.85      1343\n",
      "\n",
      "    accuracy                           0.75      1600\n",
      "   macro avg       0.58      0.60      0.59      1600\n",
      "weighted avg       0.78      0.75      0.76      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_train_preds))\n",
    "print(metrics.classification_report(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import metrics\n",
    "metrics.plot_roc_curve(best_model, X_train, y_train)\n",
    "plt.show() \n",
    "metrics.plot_roc_curve(best_model, X_val, y_val)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = best_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs = best_model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': range(0,3799), 'TARGET_5Yrs': [p[1] for p in y_test_probs]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../reports/aj_' + experiment_label + 'submission.csv',\n",
    "                 index=False,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
