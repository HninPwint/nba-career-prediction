{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBA Career Prediction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = 'xgb02e1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aim:\n",
    "* To improve on 0.71259 on Kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "\n",
    "Retain -ve values, apply SMOTE & under sampling pipeline, search on roc_auc.\n",
    "Results train, val auc:\n",
    "* (02a) SMOTE, under = 0.50, 0.75 : 0.98, 0.67. On Kaggle test = 0.66605. Terrible!\n",
    "* (02b) SMOTE in opt space (0.3), under = 1.0 : 0.96, 0.63\n",
    "* (02c) SMOTE in opt space (0.5), under = 0.75 : 0.81, 0.68\n",
    "* (02d) SMOTE 0.4 and under in opt space (0.7): 0.96, 0.67\n",
    "\n",
    "* (02e) bigger cv chunks? cv=5, SMOTE, under = 0.50, 0.75 : 0.72, 0.70. On Kaggle test = 0.70890.\n",
    "* (02f) cv=6 : 0.73, 0.69.\n",
    "* (02g) cv=4 : 0.72, 0.68.\n",
    "\n",
    "* (02e1) using e, change neg values into abs value : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load  # simpler than pickle!\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "data_path = '../data/raw/uts-advdsi-nba-career-prediction'\n",
    "\n",
    "train_raw = pd.read_csv(data_path + '/train.csv')\n",
    "test_raw = pd.read_csv(data_path + '/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 22)\n",
      "(3799, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10556</td>\n",
       "      <td>3799</td>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5342</td>\n",
       "      <td>3800</td>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5716</td>\n",
       "      <td>3801</td>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13790</td>\n",
       "      <td>3802</td>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5470</td>\n",
       "      <td>3803</td>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_old    Id  GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA  ...  FTA   FT%  \\\n",
       "0   10556  3799  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  ...  2.9  72.1   \n",
       "1    5342  3800  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  ...  3.6  67.8   \n",
       "2    5716  3801  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  ...  0.6  75.7   \n",
       "3   13790  3802  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  ...  1.5  66.9   \n",
       "4    5470  3803  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  ...  0.5  54.0   \n",
       "\n",
       "   OREB  DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.2   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.6   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   0.6   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   0.8   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.4   2.7  4.9  0.4  0.4  0.6  0.7            1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shapes & head\n",
    "\n",
    "print(train_raw.shape)\n",
    "print(test_raw.shape)\n",
    "\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8194</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8196</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8197</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id_old  Id  GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA  ...  FTM  FTA  \\\n",
       "0       1   0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3  ...  0.7  1.2   \n",
       "1    8194   1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  ...  1.8  2.5   \n",
       "2       3   2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  ...  1.8  2.7   \n",
       "3    8196   3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  ...  4.5  6.3   \n",
       "4    8197   4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  ...  1.1  1.3   \n",
       "\n",
       "    FT%  OREB  DREB  REB  AST  STL  BLK  TOV  \n",
       "0  63.4   1.2   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1  75.3   0.5   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2  71.2   1.3   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3  70.9   1.5   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4  76.9   0.2   0.6  0.9  1.5  0.5 -0.4  0.9  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 22 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Id_old       8000 non-null   int64  \n",
      " 1   Id           8000 non-null   int64  \n",
      " 2   GP           8000 non-null   int64  \n",
      " 3   MIN          8000 non-null   float64\n",
      " 4   PTS          8000 non-null   float64\n",
      " 5   FGM          8000 non-null   float64\n",
      " 6   FGA          8000 non-null   float64\n",
      " 7   FG%          8000 non-null   float64\n",
      " 8   3P Made      8000 non-null   float64\n",
      " 9   3PA          8000 non-null   float64\n",
      " 10  3P%          8000 non-null   float64\n",
      " 11  FTM          8000 non-null   float64\n",
      " 12  FTA          8000 non-null   float64\n",
      " 13  FT%          8000 non-null   float64\n",
      " 14  OREB         8000 non-null   float64\n",
      " 15  DREB         8000 non-null   float64\n",
      " 16  REB          8000 non-null   float64\n",
      " 17  AST          8000 non-null   float64\n",
      " 18  STL          8000 non-null   float64\n",
      " 19  BLK          8000 non-null   float64\n",
      " 20  TOV          8000 non-null   float64\n",
      " 21  TARGET_5Yrs  8000 non-null   int64  \n",
      "dtypes: float64(18), int64(4)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "# info\n",
    "train_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6856.971000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>62.777875</td>\n",
       "      <td>18.576663</td>\n",
       "      <td>7.267087</td>\n",
       "      <td>2.807037</td>\n",
       "      <td>6.231213</td>\n",
       "      <td>44.608900</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>0.816563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947787</td>\n",
       "      <td>71.365825</td>\n",
       "      <td>1.077838</td>\n",
       "      <td>2.168500</td>\n",
       "      <td>3.245300</td>\n",
       "      <td>1.624513</td>\n",
       "      <td>0.648688</td>\n",
       "      <td>0.245212</td>\n",
       "      <td>1.257762</td>\n",
       "      <td>0.833625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3977.447579</td>\n",
       "      <td>2309.54541</td>\n",
       "      <td>17.118774</td>\n",
       "      <td>8.935263</td>\n",
       "      <td>4.318732</td>\n",
       "      <td>1.693373</td>\n",
       "      <td>3.584559</td>\n",
       "      <td>6.155453</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>1.060964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252352</td>\n",
       "      <td>10.430447</td>\n",
       "      <td>0.785670</td>\n",
       "      <td>1.392224</td>\n",
       "      <td>2.085154</td>\n",
       "      <td>1.355986</td>\n",
       "      <td>0.407626</td>\n",
       "      <td>0.821037</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.372440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3799.00000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3413.750000</td>\n",
       "      <td>5798.75000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6787.500000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10299.250000</td>\n",
       "      <td>9798.25000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13798.000000</td>\n",
       "      <td>11798.00000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>168.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   8000.000000   8000.00000  8000.000000  8000.000000  8000.000000   \n",
       "mean    6856.971000   7798.50000    62.777875    18.576663     7.267087   \n",
       "std     3977.447579   2309.54541    17.118774     8.935263     4.318732   \n",
       "min        4.000000   3799.00000    -8.000000     2.900000     0.800000   \n",
       "25%     3413.750000   5798.75000    51.000000    12.000000     4.100000   \n",
       "50%     6787.500000   7798.50000    63.000000    16.800000     6.300000   \n",
       "75%    10299.250000   9798.25000    74.000000    23.500000     9.500000   \n",
       "max    13798.000000  11798.00000   123.000000    73.800000    34.200000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  ...   \n",
       "mean      2.807037     6.231213    44.608900     0.264525     0.816563  ...   \n",
       "std       1.693373     3.584559     6.155453     0.384093     1.060964  ...   \n",
       "min       0.300000     0.800000    21.300000    -1.100000    -3.100000  ...   \n",
       "25%       1.600000     3.600000    40.400000     0.000000     0.100000  ...   \n",
       "50%       2.400000     5.400000    44.400000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.700000     0.500000     1.500000  ...   \n",
       "max      13.100000    28.900000    67.200000     1.700000     4.700000  ...   \n",
       "\n",
       "               FTA          FT%         OREB         DREB          REB  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      1.947787    71.365825     1.077838     2.168500     3.245300   \n",
       "std       1.252352    10.430447     0.785670     1.392224     2.085154   \n",
       "min       0.000000   -13.300000     0.000000     0.200000     0.300000   \n",
       "25%       1.000000    65.000000     0.500000     1.100000     1.700000   \n",
       "50%       1.700000    71.400000     0.900000     1.900000     2.800000   \n",
       "75%       2.600000    77.500000     1.500000     2.900000     4.300000   \n",
       "max      11.100000   168.900000     5.500000    11.000000    15.900000   \n",
       "\n",
       "               AST          STL          BLK          TOV  TARGET_5Yrs  \n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  \n",
       "mean      1.624513     0.648688     0.245212     1.257762     0.833625  \n",
       "std       1.355986     0.407626     0.821037     0.723270     0.372440  \n",
       "min       0.000000     0.000000   -17.900000     0.100000     0.000000  \n",
       "25%       0.700000     0.300000     0.100000     0.700000     1.000000  \n",
       "50%       1.300000     0.600000     0.200000     1.100000     1.000000  \n",
       "75%       2.200000     0.900000     0.400000     1.600000     1.000000  \n",
       "max      12.800000     3.600000    18.900000     5.300000     1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variable descriptions\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "      <td>3799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7010.614109</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>62.853909</td>\n",
       "      <td>18.650224</td>\n",
       "      <td>7.328034</td>\n",
       "      <td>2.835404</td>\n",
       "      <td>6.302580</td>\n",
       "      <td>44.599079</td>\n",
       "      <td>0.255962</td>\n",
       "      <td>0.796920</td>\n",
       "      <td>...</td>\n",
       "      <td>1.399842</td>\n",
       "      <td>1.953567</td>\n",
       "      <td>71.612924</td>\n",
       "      <td>1.096025</td>\n",
       "      <td>2.179495</td>\n",
       "      <td>3.275783</td>\n",
       "      <td>1.636483</td>\n",
       "      <td>0.653593</td>\n",
       "      <td>0.257726</td>\n",
       "      <td>1.257910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3954.173641</td>\n",
       "      <td>1096.821164</td>\n",
       "      <td>17.151740</td>\n",
       "      <td>8.727259</td>\n",
       "      <td>4.294724</td>\n",
       "      <td>1.688427</td>\n",
       "      <td>3.579221</td>\n",
       "      <td>6.040168</td>\n",
       "      <td>0.380987</td>\n",
       "      <td>1.052862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926140</td>\n",
       "      <td>1.250376</td>\n",
       "      <td>10.457336</td>\n",
       "      <td>0.785678</td>\n",
       "      <td>1.371935</td>\n",
       "      <td>2.070646</td>\n",
       "      <td>1.335496</td>\n",
       "      <td>0.410573</td>\n",
       "      <td>0.639660</td>\n",
       "      <td>0.712449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>25.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3644.000000</td>\n",
       "      <td>949.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7062.000000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10402.500000</td>\n",
       "      <td>2848.500000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.300000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13792.000000</td>\n",
       "      <td>3798.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>74.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>127.100000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean    7010.614109  1899.000000    62.853909    18.650224     7.328034   \n",
       "std     3954.173641  1096.821164    17.151740     8.727259     4.294724   \n",
       "min        1.000000     0.000000     6.000000     3.700000     0.700000   \n",
       "25%     3644.000000   949.500000    51.000000    12.200000     4.200000   \n",
       "50%     7062.000000  1899.000000    63.000000    17.000000     6.400000   \n",
       "75%    10402.500000  2848.500000    74.000000    23.300000     9.400000   \n",
       "max    13792.000000  3798.000000   126.000000    68.000000    33.000000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000  ...   \n",
       "mean      2.835404     6.302580    44.599079     0.255962     0.796920  ...   \n",
       "std       1.688427     3.579221     6.040168     0.380987     1.052862  ...   \n",
       "min       0.300000     0.800000    25.100000    -1.000000    -2.700000  ...   \n",
       "25%       1.600000     3.700000    40.500000     0.000000     0.100000  ...   \n",
       "50%       2.500000     5.500000    44.600000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.500000     0.500000     1.500000  ...   \n",
       "max      13.400000    26.200000    74.600000     1.600000     4.300000  ...   \n",
       "\n",
       "               FTM          FTA          FT%         OREB         DREB  \\\n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000   \n",
       "mean      1.399842     1.953567    71.612924     1.096025     2.179495   \n",
       "std       0.926140     1.250376    10.457336     0.785678     1.371935   \n",
       "min       0.000000     0.000000    23.700000     0.000000     0.200000   \n",
       "25%       0.700000     1.000000    65.000000     0.500000     1.200000   \n",
       "50%       1.200000     1.700000    71.500000     0.900000     1.900000   \n",
       "75%       1.900000     2.600000    78.000000     1.500000     2.900000   \n",
       "max       7.800000     9.800000   127.100000     6.900000    12.000000   \n",
       "\n",
       "               REB          AST          STL          BLK          TOV  \n",
       "count  3799.000000  3799.000000  3799.000000  3799.000000  3799.000000  \n",
       "mean      3.275783     1.636483     0.653593     0.257726     1.257910  \n",
       "std       2.070646     1.335496     0.410573     0.639660     0.712449  \n",
       "min       0.300000     0.000000     0.000000    -7.100000     0.100000  \n",
       "25%       1.800000     0.600000     0.400000     0.100000     0.700000  \n",
       "50%       2.800000     1.300000     0.600000     0.200000     1.100000  \n",
       "75%       4.300000     2.300000     0.900000     0.400000     1.600000  \n",
       "max      18.500000     9.000000     2.700000    14.800000     5.200000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n",
    "\n",
    "We will retain all potential features, when using non-linear models.\n",
    "\n",
    "and TARGET_5Yrs is our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_raw.copy()\n",
    "test = test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_drop = ['Id_old', 'Id'] #, 'MIN', 'FGM', 'FGA', 'TOV', '3PA', 'FTM', 'FTA', 'REB']\n",
    "train.drop(cols_drop, axis=1, inplace=True)\n",
    "test.drop(cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  22.6  2.0  2.9  72.1   2.2   \n",
       "1  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  34.9  2.4  3.6  67.8   3.6   \n",
       "2  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  34.3  0.4  0.6  75.7   0.6   \n",
       "3  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  23.7  0.9  1.5  66.9   0.8   \n",
       "4  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  13.7  0.2  0.5  54.0   2.4   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.7  4.9  0.4  0.4  0.6  0.7            1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3   7.3  0.7  1.2  63.4   1.2   \n",
       "1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  35.1  1.8  2.5  75.3   0.5   \n",
       "2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  44.8  1.8  2.7  71.2   1.3   \n",
       "3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  13.5  4.5  6.3  70.9   1.5   \n",
       "4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4   0.6  0.9  1.5  0.5 -0.4  0.9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative values do not make sense in this context\n",
    "\n",
    "def clean_negatives(strategy, df):\n",
    "    \n",
    "    if strategy=='abs':\n",
    "        df = abs(df)\n",
    "    if strategy=='null':\n",
    "        df[df < 0] = None\n",
    "    if strategy=='mean':\n",
    "        df[df < 0] = None\n",
    "        df.fillna(df.mean(), inplace=True)      \n",
    "    \n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_strategy = ''\n",
    "\n",
    "train = clean_negatives(negatives_strategy, train)\n",
    "test = clean_negatives(negatives_strategy, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>24.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>21.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>55.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>75.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>17.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  80  24.3   7.8  3.0  6.4  45.7      0.1  0.3  22.6  2.0  2.9  72.1   2.2   \n",
       "1  75  21.8  10.5  4.2  7.9  55.1     -0.3 -1.0  34.9  2.4  3.6  67.8   3.6   \n",
       "2  85  19.1   4.5  1.9  4.5  42.8      0.4  1.2  34.3  0.4  0.6  75.7   0.6   \n",
       "3  63  19.1   8.2  3.5  6.7  52.5      0.3  0.8  23.7  0.9  1.5  66.9   0.8   \n",
       "4  63  17.8   3.7  1.7  3.4  50.8      0.5  1.4  13.7  0.2  0.5  54.0   2.4   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  TARGET_5Yrs  \n",
       "0   2.0  3.8  3.2  1.1  0.2  1.6            1  \n",
       "1   3.7  6.6  0.7  0.5  0.6  1.4            1  \n",
       "2   1.8  2.4  0.8  0.4  0.2  0.6            1  \n",
       "3   2.0  3.0  1.8  0.4  0.1  1.9            1  \n",
       "4   2.7  4.9  0.4  0.4  0.6  0.7            1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
       "0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3   7.3  0.7  1.2  63.4   1.2   \n",
       "1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  35.1  1.8  2.5  75.3   0.5   \n",
       "2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  44.8  1.8  2.7  71.2   1.3   \n",
       "3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  13.5  4.5  6.3  70.9   1.5   \n",
       "4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  38.7  1.1  1.3  76.9   0.2   \n",
       "\n",
       "   DREB  REB  AST  STL  BLK  TOV  \n",
       "0   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4   0.6  0.9  1.5  0.5 -0.4  0.9  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.pop('TARGET_5Yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:(8000, 19)\n",
      "test:(3799, 19)\n"
     ]
    }
   ],
   "source": [
    "#examine shapes\n",
    "\n",
    "print('train:' + str(train.shape))\n",
    "print('test:' + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 6669, 0: 1331})\n"
     ]
    }
   ],
   "source": [
    "# target class balance check\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(train_target)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformations\n",
    "\n",
    "# scaling - not for tree-based model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training data and validation data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train_target, test_size=0.2, random_state=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from xgboost) (1.5.3)\n"
     ]
    }
   ],
   "source": [
    "#import models\n",
    "\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.010518407212622\n"
     ]
    }
   ],
   "source": [
    "#Class balancing\n",
    "\n",
    "class_weight = counter[1.0] / counter[0.0]\n",
    "print(class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "initial_model = xgb.XGBClassifier(#scale_pos_weight = class_weight,\n",
    "                                 use_label_encoder=False,\n",
    "                                 seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index the y_train, since xgboost has deprecated the use_label_encoder function\n",
    "\n",
    "y_train.index = range(0, len(y_train), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:39:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=6, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "initial_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(initial_model,  '../models/aj_' + experiment_label + '_initial.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = initial_model.predict(X_train)\n",
    "y_val_preds = initial_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.models.aj_metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "        pred:0  pred:1\n",
      "true:0     937     137\n",
      "true:1       0    5326\n",
      "Val:\n",
      "        pred:0  pred:1\n",
      "true:0      23     234\n",
      "true:1      64    1279\n"
     ]
    }
   ],
   "source": [
    "# Show TRAINING confusion matrix with labels\n",
    "\n",
    "print(\"Training:\")\n",
    "print(confusion_matrix(y_train, y_train_preds))\n",
    "\n",
    "print(\"Val:\")\n",
    "print(confusion_matrix(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1074\n",
      "           1       0.97      1.00      0.99      5326\n",
      "\n",
      "    accuracy                           0.98      6400\n",
      "   macro avg       0.99      0.94      0.96      6400\n",
      "weighted avg       0.98      0.98      0.98      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.09      0.13       257\n",
      "           1       0.85      0.95      0.90      1343\n",
      "\n",
      "    accuracy                           0.81      1600\n",
      "   macro avg       0.55      0.52      0.51      1600\n",
      "weighted avg       0.75      0.81      0.77      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_train_preds))\n",
    "print(metrics.classification_report(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.5.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in /opt/conda/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# class imbalance pipeline\n",
    "\n",
    "!pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "      \n",
    "    xgboost = xgb.XGBClassifier(\n",
    "        max_depth = int(space['max_depth']),\n",
    "        learning_rate = space['learning_rate'],\n",
    "        min_child_weight = space['min_child_weight'],\n",
    "        gamma = space['gamma'],\n",
    "        subsample = space['subsample'],\n",
    "        colsample_bytree = space['colsample_bytree'],\n",
    "        #scale_pos_weight = space['scale_pos_weight'],\n",
    "        use_label_encoder=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Define model pipeline\n",
    "    model = Pipeline([\n",
    "        ('over', SMOTE(sampling_strategy=0.5)),\n",
    "        ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
    "        ('model', xgboost)\n",
    "    ])\n",
    "    \n",
    "    acc = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\").mean()\n",
    "\n",
    "    return{'loss': 1-acc, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth' : hp.choice('max_depth', range(5, 20, 1)),\n",
    "    'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.05),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'gamma' : hp.quniform('gamma', 0, 0.1, 0.01),\n",
    "    'subsample' : hp.quniform('subsample', 0.1, 1, 0.05),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.05)\n",
    "    #'scale_pos_weight' : hp.quniform('scale_pos_weight', 1, class_weight, class_weight / 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:39:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:39:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.93s/trial, best loss: 0.3503059375620452]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "    fn=objective,   \n",
    "    space=space,       \n",
    "    algo=tpe.suggest,       \n",
    "    max_evals=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:  {'colsample_bytree': 0.8500000000000001, 'gamma': 0.03, 'learning_rate': 0.35000000000000003, 'max_depth': 4, 'min_child_weight': 2.0, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: \", best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:39:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1607604574104/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('over', SMOTE(sampling_strategy=0.5)),\n",
       "                ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
       "                ('model',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.8500000000000001, gamma=0.03,\n",
       "                               gpu_id=-1, importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.35000000000000003,\n",
       "                               max_delta_step=0, max_depth=4,\n",
       "                               min_child_weight=2.0, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=6, num_parallel_tree=1, random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=42, subsample=0.9, tree_method='exact',\n",
       "                               use_label_encoder=False, validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### and here is where we take the best hyperparamters from the hyperparameter search and fit the model again.\n",
    "\n",
    "xgboost_2 = xgb.XGBClassifier(\n",
    "    max_depth = best['max_depth'],\n",
    "    learning_rate = best['learning_rate'],\n",
    "    min_child_weight = best['min_child_weight'],\n",
    "    gamma = best['gamma'],    \n",
    "    subsample = best['subsample'],\n",
    "    colsample_bytree = best['colsample_bytree'],\n",
    "    #scale_pos_weight = best['scale_pos_weight'],\n",
    "    use_label_encoder=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Define model pipeline\n",
    "best_model = Pipeline([\n",
    "    ('over', SMOTE(sampling_strategy=0.5)),\n",
    "    ('under', RandomUnderSampler(sampling_strategy=0.75)),\n",
    "    ('model', xgboost_2)\n",
    "])\n",
    "\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to file\n",
    "\n",
    "#dump(best_model,  '../models/aj_' + experiment_label + '_best.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions for train & validation sets\n",
    "\n",
    "y_train_preds = best_model.predict(X_train)\n",
    "y_val_preds = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "        pred:0  pred:1\n",
      "true:0     634     440\n",
      "true:1     264    5062\n",
      "Val:\n",
      "        pred:0  pred:1\n",
      "true:0      51     206\n",
      "true:1     140    1203\n"
     ]
    }
   ],
   "source": [
    "# Show TRAINING confusion matrix with labels\n",
    "\n",
    "print(\"Training:\")\n",
    "print(confusion_matrix(y_train, y_train_preds))\n",
    "\n",
    "print(\"Val:\")\n",
    "print(confusion_matrix(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.59      0.64      1074\n",
      "           1       0.92      0.95      0.93      5326\n",
      "\n",
      "    accuracy                           0.89      6400\n",
      "   macro avg       0.81      0.77      0.79      6400\n",
      "weighted avg       0.88      0.89      0.89      6400\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.20      0.23       257\n",
      "           1       0.85      0.90      0.87      1343\n",
      "\n",
      "    accuracy                           0.78      1600\n",
      "   macro avg       0.56      0.55      0.55      1600\n",
      "weighted avg       0.76      0.78      0.77      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_train_preds))\n",
    "print(metrics.classification_report(y_val, y_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import metrics\n",
    "metrics.plot_roc_curve(best_model, X_train, y_train)\n",
    "plt.show() \n",
    "metrics.plot_roc_curve(best_model, X_val, y_val)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to test data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = best_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs = best_model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Id': range(0,3799), 'TARGET_5Yrs': [p[1] for p in y_test_probs]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../reports/aj_' + experiment_label + 'submission.csv',\n",
    "                 index=False,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
